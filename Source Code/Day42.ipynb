{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Apollonir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Apollonir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Apollonir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Apollonir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lý thuyết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: [[(0, 1), (1, 1), (2, 1)], [(1, 1), (2, 1), (3, 1), (4, 1)]]\n",
      "Câu 1 - Vector: [(0, 1), (1, 1), (2, 1)]\n",
      "Câu 2 - Vector: [(1, 1), (2, 1), (3, 1), (4, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Tạo một danh sách các câu\n",
    "sentences = [\n",
    "\"Tôi thích AI\",\n",
    "\"Tôi thích âm nhạc\"\n",
    "]\n",
    "\n",
    "# Chia nhỏ các câu thành các từ\n",
    "words = [word_tokenize (sentence) for sentence in sentences]\n",
    "\n",
    "# Tạo một từ điển\n",
    "dictionary = corpora.Dictionary(words)\n",
    "\n",
    "# Chuy ển đổi các câu thành các vector bag -of - words\n",
    "bow_corpus = [dictionary.doc2bow(sentence) for sentence in words]\n",
    "\n",
    "print(f'Corpus: {bow_corpus}')\n",
    "# In ra các vector bag -of - words\n",
    "for index, vector in enumerate(bow_corpus, 1):\n",
    "    print(f'Câu {index} - Vector: {vector}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Từ tương tự với \"AI\": [('nhạc', 0.17018884420394897), ('Tôi', 0.004503029398620129), ('thích', -0.027750346809625626), ('âm', -0.044617101550102234)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tạo mô hình Word2Vec\n",
    "model = Word2Vec(words, min_count=1)\n",
    "\n",
    "# In ra các từ tương tự với từ \"AI\"\n",
    "similar_words = model.wv.most_similar(\"AI\")\n",
    "print(f'Từ tương tự với \"AI\": {similar_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(0, 1), (1, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]]\n",
      "Câu 1 - Vector: [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "Câu 2 - Vector: [(0, 1), (1, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]\n"
     ]
    }
   ],
   "source": [
    "sentences =  [\"Robot của kỳ lân công nghệ Figure AI\", \n",
    "              \"Figure AI là startup mới thành lập năm 2022 tại Mỹ nhưng đã tạo ấn tượng mạnh với giới đầu tư\"]\n",
    "\n",
    "words = [word_tokenize(sentence) for sentence in sentences]\n",
    "dictionary = corpora.Dictionary(words)\n",
    "bow_corpus = [dictionary.doc2bow(sentence) for sentence in words]\n",
    "\n",
    "print(f'Corpus: {bow_corpus}')\n",
    "# In ra các vector bag -of - words\n",
    "for index, vector in enumerate(bow_corpus, 1):\n",
    "    print(f'Câu {index} - Vector: {vector}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Từ tương tự với \"Robot\": [('của', 0.2008291333913803), ('lân', 0.17751173675060272), ('giới', 0.11886844784021378), ('đã', 0.11025070399045944), ('mạnh', 0.10132687538862228), ('công', 0.09661101549863815), ('là', 0.08376450091600418), ('ấn', 0.08254542946815491), ('Mỹ', 0.07622206956148148), ('mới', 0.07315012812614441)]\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(words, min_count=1)\n",
    "\n",
    "similar_words = model.wv.most_similar(\"Robot\")\n",
    "print(f'Từ tương tự với \"Robot\": {similar_words}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
