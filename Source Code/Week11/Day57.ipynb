{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\n",
    "\n",
    "Trong đó:\n",
    "- $x_i$ và $y_i$ là các giá trị của biến $x$ và $y$\n",
    "- $\\bar{x}$ và $\\bar{y}$ là giá trị trung bình của $x$ và $y$\n",
    "- $n$ là số lượng cặp giá trị $(x_i, y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pearson_correlation(x, y):\n",
    "    # Tính giá trị trung bình\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "    \n",
    "    # Tính tử số (numerator)\n",
    "    numerator = np.sum((x - mean_x) * (y - mean_y))\n",
    "    \n",
    "    # Tính mẫu số (denominator)\n",
    "    sum_x_squared = np.sum((x - mean_x) ** 2)\n",
    "    sum_y_squared = np.sum((y - mean_y) ** 2)\n",
    "    denominator = np.sqrt(sum_x_squared * sum_y_squared)\n",
    "    \n",
    "    # Tính hệ số tương quan\n",
    "    r = numerator / denominator\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "result = pearson_correlation(x, y)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([10, 8, 6, 4, 2])\n",
    "\n",
    "result = pearson_correlation(x, y)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07589466694797184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 10, 100) \n",
    "y = np.sin(x) \n",
    "\n",
    "result = pearson_correlation(x, y)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900317180760643"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = np.array([1.1, 1.9, 3.2, 4.5, 5.1])\n",
    "label = np.array([1.0, 2.0, 3.0, 4.1, 5.3])\n",
    "\n",
    "result = pearson_correlation(feature, label)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height = np.array([150, 160, 170, 180, 190])\n",
    "weight = np.array([50, 60, 70, 80, 90])\n",
    "    \n",
    "result = pearson_correlation(height, weight)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedA = np.array([0.3, 0.5, 0.7, 0.8])\n",
    "embedB = np.array([0.4, 0.6, 0.8, 0.9])\n",
    "\n",
    "result = pearson_correlation(embedA, embedB)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.034032500978822516"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)  \n",
    "x= np.random.random(100)  \n",
    "y = np.random.random(100)\n",
    "\n",
    "result = pearson_correlation(x, y)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(100)\n",
    "\n",
    "np.random.seed(42)\n",
    "noise = np.random.normal(0, 10, 100)  # Gaussian noise với mean=0, std=10\n",
    "\n",
    "# Tạo 2 biến y\n",
    "y_clean = x  # y = x (không có nhiễu)\n",
    "y_noisy = x + noise  # y = x + nhiễu\n",
    "\n",
    "# Tính hệ số tương quan\n",
    "corr_clean = pearson_correlation(x, y_clean)\n",
    "corr_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555806401406204"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_noisy = pearson_correlation(x, y_noisy)\n",
    "corr_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = np.array([22, 24, 23, 25, 26])\n",
    "sales = np.array([100, 110, 105, 115, 120])\n",
    "\n",
    "result = pearson_correlation(temperature, sales)\n",
    "result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"deep learning for natural language processing\"\n",
    "doc2 = \"transformer models improve language understanding\"\n",
    "doc3 = \"convolutional neural networks for image classification\"\n",
    "query = \"language models for text understanding\"\n",
    "\n",
    "# Danh sách tất cả văn bản kể cả query\n",
    "all_docs = [doc1, doc2, doc3, query]\n",
    "doc_names = [\"doc1\", \"doc2\", \"doc3\", \"query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Tiền xử lý văn bản\n",
    "def preprocess_text(text):\n",
    "    # Chuyển về chữ thường\n",
    "    text = text.lower()\n",
    "    # Tách từ\n",
    "    words = text.split()\n",
    "    return words\n",
    "\n",
    "# Hàm tính TF (Term Frequency)\n",
    "def calculate_tf(document):\n",
    "    words = preprocess_text(document)\n",
    "    word_counts = Counter(words)\n",
    "    total_words = len(words)\n",
    "    tf_dict = {word: count/total_words for word, count in word_counts.items()}\n",
    "    return tf_dict\n",
    "\n",
    "# Hàm tính IDF (Inverse Document Frequency)\n",
    "def calculate_idf(documents):\n",
    "    idf_dict = {}\n",
    "    N = len(documents)\n",
    "    word_in_docs = {}\n",
    "    \n",
    "    # Đếm số lượng văn bản chứa mỗi từ\n",
    "    for doc in documents:\n",
    "        words = set(preprocess_text(doc))  \n",
    "        for word in words:\n",
    "            word_in_docs[word] = word_in_docs.get(word, 0) + 1\n",
    "    \n",
    "    # Tính IDF cho mỗi từ\n",
    "    for word, doc_freq in word_in_docs.items():\n",
    "        idf_dict[word] = math.log(N / (1 + doc_freq))\n",
    "    \n",
    "    return idf_dict\n",
    "\n",
    "# Tính TF-IDF cho mỗi văn bản\n",
    "def calculate_tfidf(documents):\n",
    "    idf = calculate_idf(documents)\n",
    "    tfidf_vectors = []\n",
    "    \n",
    "    # Tạo danh sách tất cả các từ duy nhất\n",
    "    all_words = set()\n",
    "    for doc in documents:\n",
    "        all_words.update(preprocess_text(doc))\n",
    "    all_words = sorted(list(all_words))\n",
    "    \n",
    "    # Tính TF-IDF cho mỗi văn bản\n",
    "    for doc in documents:\n",
    "        tf = calculate_tf(doc)\n",
    "        tfidf = [tf.get(word, 0) * idf.get(word, 0) for word in all_words]\n",
    "        tfidf_vectors.append(tfidf)\n",
    "    \n",
    "    return tfidf_vectors, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors, vocabulary = calculate_tfidf(all_docs)\n",
    "query_vector = tfidf_vectors[3] \n",
    "correlations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doc2', 0.014382960777356483),\n",
       " ('doc2', 0.014382960777356483),\n",
       " ('doc1', -0.247921511957806),\n",
       " ('doc1', -0.247921511957806),\n",
       " ('doc3', -0.28950995294112053),\n",
       " ('doc3', -0.28950995294112053)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(3):  # chỉ xét 3 văn bản đầu tiên (không tính query)\n",
    "    correlation = pearson_correlation(tfidf_vectors[i], query_vector)\n",
    "    correlations.append((doc_names[i], correlation))\n",
    "\n",
    "correlations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
